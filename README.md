#  Sentiment Analysis ‚Äì End-to-End MLOps Pipeline

A fully production-style Machine Learning + MLOps workflow built using AWS, Kubernetes, MLflow, DVC, GitHub Actions, Docker, and real monitoring tools like Prometheus & Grafana.

This project demonstrates how a text-classification ML model can be developed, tracked, deployed, and monitored using modern MLOps practices.

# 1. Project Overview

This project implements an end-to-end MLOps pipeline for Sentiment Analysis that automates:

Data ingestion from AWS S3

Preprocessing & Feature Engineering (NLP + TF-IDF)

Model training, evaluation & versioning

Reproducible ML pipelines using DVC

CI pipeline execution using GitHub Actions

Containerization with Docker

Deployment on AWS EKS (Kubernetes)

Monitoring & alerting using Prometheus + Grafana

It mimics the workflow followed by ML Engineers and MLOps teams in real-world production systems.

# 2. Architecture Diagram
AWS S3 ‚Üí DVC Pipeline ‚Üí Preprocessing ‚Üí Feature Engineering ‚Üí Model Training
      ‚Üí MLflow Tracking ‚Üí Model Registry ‚Üí CI/CD ‚Üí Docker ‚Üí AWS ECR ‚Üí AWS EKS
      ‚Üí Prometheus Monitoring ‚Üí Grafana Dashboards

# 3. End-to-End Workflow
# Data Ingestion

Raw dataset stored in AWS S3

Pulled into pipeline using DVC (dvc repro)

# Data Preprocessing & Feature Engineering

Text cleaning

Tokenization

TF-IDF Vectorization

Dataset splitting

# Model Training & Evaluation

Logistic Regression / SVM / Naive Bayes

Cross-validation

MLflow used for:

Experiment tracking

Metrics logging

Parameter tracking

Model versioning

# Model Registry & Promotion

Best model automatically promoted to production through CI pipeline

Stored in MLflow‚Äôs Model Registry

# 4. CI/CD Pipeline (GitHub Actions)

Every push triggers:

üîπ CI Stage

Run DVC pipeline

Run ML tests (tests/test_model.py)

Run API tests (tests/test_flask_app.py)

Register & promote model if tests pass

üîπ CD Stage

Build Docker image

Push to AWS ECR

Update deployment on AWS EKS

Kubernetes rollout update

This ensures fully automated, reproducible deployment with every commit.

# 5. AWS Deployment (EKS + EC2)

Kubernetes cluster created using AWS EKS

Nodes running on EC2

App deployed as a Kubernetes Deployment + Service

Secrets managed via Kubernetes Secret

Auto-updates triggered by CI/CD

# 6. Monitoring & Alerting

Metrics collected via:

Prometheus ‚Üí scrapes application & system metrics

Grafana ‚Üí dashboards for:

Model latency

Prediction throughput

API status

Pod health

Resource consumption

Alerts can be configured for:
‚ö†Ô∏è High error rate
‚ö†Ô∏è High latency
‚ö†Ô∏è Pod crash loops

# 7. Tech Stack
Languages & ML

Python

Scikit-learn

NLP (TF-IDF)

MLOps Tools

MLflow

DVC

GitHub Actions

Docker

Cloud & Deployment

AWS S3

AWS ECR

AWS EC2

AWS EKS

Kubernetes

Monitoring

Prometheus

Grafana

API

Flask REST API

‚ñ∂Ô∏è 8. Run Project Locally
1Ô∏è‚É£ Create a virtual environment
python -m venv venv
source venv/bin/activate

2Ô∏è‚É£ Install dependencies
pip install -r requirements.txt

3Ô∏è‚É£ Reproduce pipeline
dvc repro

4Ô∏è‚É£ Run Flask API
python app.py

# 9. Docker Build
docker build -t sentiment-app .
docker run -p 5000:5000 sentiment-app

# 10. Deploy to Kubernetes (EKS)
Update kubeconfig:
aws eks update-kubeconfig --region us-east-1 --name flask-app-cluster

Apply deployment:
kubectl apply -f deployment.yaml

# 11. Monitoring

Prometheus:

kubectl port-forward svc/prometheus-service 9090:9090


Grafana:

kubectl port-forward svc/grafana-service 3000:3000

# 12. Features

‚úî End-to-end automated ML pipeline
‚úî Model registry + version control
‚úî Fully containerized
‚úî CI/CD with GitHub Actions
‚úî Production-grade Kubernetes deployment
‚úî Monitoring + alerting
‚úî Cloud-native architecture

# 13. Future Improvements

Add drift detection

Add model re-training triggers

Implement feature store

Deploy to multi-node cluster

Integrate FastAPI instead of Flask

# Acknowledgement

Special thanks to Vikash Das for his step-by-step tutorial that guided the entire project structure and workflow.
